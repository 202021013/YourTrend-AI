import streamlit as st
import os
from openai import OpenAI
from dotenv import load_dotenv
from typing import Dict, List

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

class IdeaGenerationAgent:
    def __init__(self):
        self.situation_prompts = {
            "ìƒˆë¡œìš´ ì œí’ˆ ì•„ì´ë””ì–´": {
                "prompt": "ìƒˆë¡œìš´ ì œí’ˆ ì•„ì´ë””ì–´ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.",
                "considerations": ["ì‹œì¥ ìˆ˜ìš”", "ê²½ìŸ ì œí’ˆ", "ê¸°ìˆ ì  ê°€ëŠ¥ì„±"]
            },
            "ë§ˆì¼€íŒ… ì „ëµ": {
                "prompt": "íš¨ê³¼ì ì¸ ë§ˆì¼€íŒ… ì „ëµì„ ì œì‹œí•´ì£¼ì„¸ìš”.",
                "considerations": ["íƒ€ê²Ÿ ê³ ê°", "ê´‘ê³  ì±„ë„", "ì˜ˆì‚°"]
            }
        }
        
        # ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì¶”ê°€
        self.custom_prompt_templates = {
            "ì°½ì˜ì„± ê°•í™”": "ë” ì°½ì˜ì ì´ê³  í˜ì‹ ì ì¸ ì•„ì´ë””ì–´ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.",
            "ì‹¤ìš©ì„± ê°•í™”": "ë” í˜„ì‹¤ì ì´ê³  ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì•„ì´ë””ì–´ë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”.",
            "ë¹„ìš© íš¨ìœ¨ì„±": "ë¹„ìš© ëŒ€ë¹„ íš¨ê³¼ê°€ ë†’ì€ ë°©ì•ˆì„ ì¤‘ì‹¬ìœ¼ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”.",
            "ë¹ ë¥¸ ì‹¤í–‰": "ë‹¨ê¸°ê°„ì— ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ë°©ì•ˆì„ ì¤‘ì‹¬ìœ¼ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”.",
            "ìœ„í—˜ ìµœì†Œí™”": "ë¦¬ìŠ¤í¬ë¥¼ ìµœì†Œí™”í•  ìˆ˜ ìˆëŠ” ë°©ì•ˆì„ ì¤‘ì‹¬ìœ¼ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”.",
            "í™•ì¥ì„±": "í–¥í›„ í™•ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ ë°©ì•ˆì„ ì¤‘ì‹¬ìœ¼ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”.",
            "ì‚¬ìš©ì ì •ì˜": "ì§ì ‘ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."
        }

    def analyze_and_generate(self, text: str, situation: str, custom_prompt: str = "") -> Dict[str, str]:
        """ì„ íƒëœ ìƒí™©ê³¼ ì¶”ê°€ í”„ë¡¬í”„íŠ¸ì— ë”°ë¼ ì•„ì´ë””ì–´ë¥¼ ìƒì„±"""
        prompt_data = self.situation_prompts[situation]
        base_prompt = f"""
{prompt_data['prompt']}

ê³ ë ¤ì‚¬í•­:
{', '.join(prompt_data['considerations'])}

ì¶”ê°€ ìš”êµ¬ì‚¬í•­:
{custom_prompt}

ì‘ë‹µì€ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”í•´ì£¼ì„¸ìš”:
1. ìƒí™© ë¶„ì„
2. í•µì‹¬ ì•„ì´ë””ì–´
3. ì‹¤í–‰ ë°©ì•ˆ
4. ê¸°ëŒ€ íš¨ê³¼
5. ê³ ë ¤ì‚¬í•­
"""

        try:
            response = client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": base_prompt},
                    {"role": "user", "content": f"ë‹¤ìŒ ë‚´ìš©ì„ {situation} ê´€ì ì—ì„œ ë¶„ì„í•˜ê³  ì•„ì´ë””ì–´ë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”:\n\n{text}"}
                ],
                temperature=0.8,
                max_tokens=1000
            )
            return self._parse_response(response.choices[0].message.content)
        except Exception as e:
            return {"error": f"ì•„ì´ë””ì–´ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}

    def generate_variations(self, idea: str) -> List[str]:
        """ì•„ì´ë””ì–´ì˜ ë³€í˜•ì„ ìƒì„±"""
        try:
            response = client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "ì£¼ì–´ì§„ ì•„ì´ë””ì–´ì˜ ìƒˆë¡œìš´ ë³€í˜•ì„ ìƒì„±í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": f"ë‹¤ìŒ ì•„ì´ë””ì–´ì˜ ë³€í˜•ì„ 3ê°€ì§€ ì œì‹œí•´ì£¼ì„¸ìš”:\n\n{idea}"}
                ],
                temperature=0.9,
                max_tokens=500
            )
            return self._extract_variations(response.choices[0].message.content)
        except Exception as e:
            return [f"ë³€í˜• ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"]

    def _parse_response(self, response: str) -> Dict[str, str]:
        sections = response.split("\n\n")
        result = {}
        for section in sections:
            if section.strip():
                title, content = section.split("\n", 1)
                result[title.strip()] = content.strip()
        return result

    def _extract_variations(self, response: str) -> List[str]:
        return [variation.strip() for variation in response.split("\n") if variation.strip()]

def main():
    st.title("ğŸ’¡ ìƒí™©ë³„ AI ì•„ì´ë””ì–´ ìƒì„±ê¸°")
    
    if 'idea_agent' not in st.session_state:
        st.session_state.idea_agent = IdeaGenerationAgent()

    # ì‚¬ì´ë“œë°” êµ¬ì„±
    with st.sidebar:
        st.subheader("ğŸ¯ ìƒí™© ì„ íƒ")
        selected_situation = st.selectbox(
            "ì•„ì´ë””ì–´ê°€ í•„ìš”í•œ ìƒí™©ì„ ì„ íƒí•˜ì„¸ìš”:",
            options=list(st.session_state.idea_agent.situation_prompts.keys())
        )
        
        # ì„ íƒëœ ìƒí™©ì˜ ê³ ë ¤ì‚¬í•­ í‘œì‹œ
        st.markdown("---")
        st.subheader("ğŸ” ì£¼ìš” ê³ ë ¤ì‚¬í•­")
        for consideration in st.session_state.idea_agent.situation_prompts[selected_situation]["considerations"]:
            st.write(f"- {consideration}")

    # ë©”ì¸ ì˜ì—­
    st.subheader("1ï¸âƒ£ ìƒí™© ì„¤ëª…")
    input_text = st.text_area(
        "í˜„ì¬ ìƒí™©ì´ë‚˜ ê³ ë¯¼ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”:",
        height=150,
        help=f"ì„ íƒí•˜ì‹  '{selected_situation}' ìƒí™©ì— ëŒ€í•´ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”."
    )

    # ì¶”ê°€ í”„ë¡¬í”„íŠ¸ ì„¤ì •
    st.subheader("2ï¸âƒ£ ì¶”ê°€ ìš”êµ¬ì‚¬í•­ ì„¤ì •")
    col1, col2 = st.columns([1, 1])
    
    with col1:
        prompt_template = st.selectbox(
            "í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„ íƒ:",
            options=list(st.session_state.idea_agent.custom_prompt_templates.keys()),
            key="prompt_template"
        )

    with col2:
        if prompt_template == "ì‚¬ìš©ì ì •ì˜":
            custom_prompt = st.text_input(
                "ì¶”ê°€ í”„ë¡¬í”„íŠ¸ë¥¼ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”:",
                help="AIì—ê²Œ ì£¼ê³  ì‹¶ì€ ì¶”ê°€ì ì¸ ì§€ì‹œì‚¬í•­ì„ ì…ë ¥í•˜ì„¸ìš”."
            )
        else:
            custom_prompt = st.session_state.idea_agent.custom_prompt_templates[prompt_template]
            st.text_input("ì„ íƒëœ í”„ë¡¬í”„íŠ¸:", value=custom_prompt, disabled=True)

    # í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸°
    with st.expander("ğŸ” ìµœì¢… í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸°", expanded=False):
        st.markdown(f"""
        **ì„ íƒëœ ìƒí™©**: {selected_situation}
        
        **ì¶”ê°€ ìš”êµ¬ì‚¬í•­**: {custom_prompt}
        
        **ì£¼ìš” ê³ ë ¤ì‚¬í•­**:
        {', '.join(st.session_state.idea_agent.situation_prompts[selected_situation]["considerations"])}
        """)

    # ì‹¤í–‰ ë²„íŠ¼
    col3, col4 = st.columns([1, 1])
    
    with col3:
        analyze_button = st.button("ì•„ì´ë””ì–´ ìƒì„±", type="primary")
    with col4:
        if st.button("ì´ˆê¸°í™”"):
            st.session_state.clear()
            st.experimental_rerun()
    
    if analyze_button and input_text:
        with st.spinner(f"'{selected_situation}' ìƒí™©ì— ëŒ€í•œ ì•„ì´ë””ì–´ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            analysis_result = st.session_state.idea_agent.analyze_and_generate(
                input_text, 
                selected_situation,
                custom_prompt
            )
            
            if "error" in analysis_result:
                st.error(analysis_result["error"])
            else:
                # ê²°ê³¼ í‘œì‹œ
                st.subheader("3ï¸âƒ£ ìƒì„±ëœ ì•„ì´ë””ì–´")
                for section, content in analysis_result.items():
                    with st.expander(section, expanded=True):
                        st.markdown(content)

    # ë„ì›€ë§
    with st.sidebar:
        st.markdown("---")
        st.subheader("ğŸ’¡ íš¨ê³¼ì ì¸ ì‚¬ìš© íŒ")
        st.markdown("""
        1. **ìƒí™© ì„ íƒ**
           - ê°€ì¥ ì í•©í•œ ìƒí™© ìœ í˜• ì„ íƒ
           - ê´€ë ¨ ê³ ë ¤ì‚¬í•­ í™•ì¸
        
        2. **ìƒí™© ì„¤ëª…**
           - êµ¬ì²´ì ì¸ ëª©í‘œì™€ ì œì•½ì‚¬í•­ í¬í•¨
           - í˜„ì¬ ìƒí™©ì„ ìƒì„¸íˆ ì„¤ëª…
        
        3. **ì¶”ê°€ ìš”êµ¬ì‚¬í•­**
           - í…œí”Œë¦¿ í™œìš© ë˜ëŠ” ì§ì ‘ ì…ë ¥
           - ì›í•˜ëŠ” ë°©í–¥ì„± ëª…í™•íˆ ì œì‹œ
        
        4. **ê²°ê³¼ í™œìš©**
           - ìƒì„±ëœ ì•„ì´ë””ì–´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì²´í™”
           - í•„ìš”ì‹œ ë‹¤ë¥¸ ê´€ì ìœ¼ë¡œ ì¬ì‹œë„
        """)

if __name__ == "__main__":
    main()