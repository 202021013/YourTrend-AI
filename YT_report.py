import streamlit as st
import yt_dlp
import whisper
from openai import OpenAI
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
import os
from pathlib import Path
from dotenv import load_dotenv
import logging
from typing import Optional
from datetime import datetime

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


class Config:
    WHISPER_MODEL = "base"
    OUTPUT_DIR = "downloads"
    AUDIO_FORMAT = "mp3"
    OPENAI_MODEL = "gpt-4o-mini"
    MAX_TEXT_LENGTH = 4000


class ConversationManager:
    def __init__(self, api_key: str):
        self.embeddings = OpenAIEmbeddings(openai_api_key=api_key)
        persist_directory = "chroma_db"
        Path(persist_directory).mkdir(parents=True, exist_ok=True)

        self.vector_store = Chroma(
            persist_directory=persist_directory,
            embedding_function=self.embeddings,
            collection_name="conversations"
        )
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )

    def add_conversation(self, text: str, metadata: dict = None):
        texts = self.text_splitter.split_text(text)
        if texts:  # í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì¶”ê°€
            self.vector_store.add_texts(
                texts,
                metadatas=[metadata] * len(texts) if metadata else None
            )

    def add_conversation(self, text: str, metadata: dict = None):
        try:
            texts = self.text_splitter.split_text(text)
            if texts:  # í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì¶”ê°€
                self.vector_store.add_texts(
                    texts,
                    metadatas=[metadata] * len(texts) if metadata else None
                )
                self.vector_store.persist()  # ë³€ê²½ì‚¬í•­ ì €ì¥
        except Exception as e:
            logger.error(f"ëŒ€í™” ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    def search_similar(self, query: str, k: int = 3):
        return self.vector_store.similarity_search(query, k=k)


class YouTubeIdeaExtractor:
    def __init__(self):
        self.OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
        if not self.OPENAI_API_KEY:
            raise ValueError(
                "OpenAI API key not found in environment variables")

        self.client = OpenAI(api_key=self.OPENAI_API_KEY)
        self.model = whisper.load_model(Config.WHISPER_MODEL)
        self.conversation_manager = ConversationManager(self.OPENAI_API_KEY)

    def search_videos_with_pagination(self, query: str, page: int = 1, per_page: int = 5) -> list:
        """
        í˜ì´ì§€ë„¤ì´ì…˜ì´ ì ìš©ëœ YouTube ì˜ìƒ ê²€ìƒ‰
        """
        try:
            ydl_opts = {
                'quiet': True,
                'extract_flat': True,
                'force_generic_extractor': False,
                'no_warnings': True,
                'playlistend': per_page * page  # ì „ì²´ ê²°ê³¼ ìˆ˜ ì¦ê°€
            }

            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                search_url = f"ytsearch{per_page * page}:{query}"
                results = ydl.extract_info(search_url, download=False)

                videos = []
                if 'entries' in results:
                    # í˜„ì¬ í˜ì´ì§€ì— í•´ë‹¹í•˜ëŠ” ê²°ê³¼ë§Œ ë°˜í™˜
                    start_idx = (page - 1) * per_page
                    end_idx = start_idx + per_page
                    entries = results['entries'][start_idx:end_idx]

                    for video in entries:
                        video_id = video.get('id', '')
                        videos.append({
                            'title': video.get('title', 'ì œëª© ì—†ìŒ'),
                            'url': f"https://www.youtube.com/watch?v={video_id}",
                            'duration': str(video.get('duration', 0)),
                            'channel': video.get('uploader', 'ì±„ë„ëª… ì—†ìŒ'),
                            'description': video.get('description', 'ì„¤ëª… ì—†ìŒ'),
                            'thumbnail': f"https://i.ytimg.com/vi/{video_id}/maxresdefault.jpg",
                            'video_id': video_id
                        })
                return videos

        except Exception as e:
            logger.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return []

    def download_and_process(self, youtube_url: str) -> str:
        output_path = Path(Config.OUTPUT_DIR)
        output_path.mkdir(parents=True, exist_ok=True)

        ydl_opts = {
            'format': 'm4a/bestaudio/best',
            'paths': {'home': str(output_path)},
            'postprocessors': [{
                'key': 'FFmpegExtractAudio',
                'preferredcodec': Config.AUDIO_FORMAT,
            }]
        }

        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(youtube_url, download=True)
            return ydl.prepare_filename(info).rsplit(".", 1)[0] + f".{Config.AUDIO_FORMAT}"

    def transcribe_audio(self, audio_path: str) -> str:
        return self.model.transcribe(audio_path)["text"]

    def analyze_with_summary(self, text: str, summary: str, similar_contexts: list) -> str:
        """ìš”ì•½ë³¸ê³¼ ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ ì‹¬ì¸µ ë¶„ì„"""
        try:
            context = "\n".join([doc.page_content for doc in similar_contexts])

            prompt = f"""í˜„ì¬ ì½˜í…ì¸ ì™€ ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ ì‹¬ì¸µ ë¶„ì„ì„ ì§„í–‰í•´ì£¼ì„¸ìš”.

    í˜„ì¬ ì½˜í…ì¸  ìš”ì•½:
    {summary}

    ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸:
    {context}

    í˜„ì¬ í…ìŠ¤íŠ¸ ì „ë¬¸:
    {text[:2000]}...

    ë‹¤ìŒ í•­ëª©ë“¤ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
    1. í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (3ê°œ)
    2. ì´ì „ ë‚´ìš©ê³¼ì˜ ì—°ê´€ì„± ë° ì°¨ì´ì 
    3. ì‹¤í–‰ ê°€ëŠ¥í•œ ì œì•ˆì‚¬í•­ (2-3ê°œ)
    4. ì¶”ê°€ íƒêµ¬ê°€ í•„ìš”í•œ ë¶€ë¶„"""

            response = self.client.chat.completions.create(
                model=Config.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ì½˜í…ì¸  ë¶„ì„ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1000,
                temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"ë¶„ì„ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None

    def extract_ideas_with_context(self, text: str, similar_contexts: list) -> str:
        context = "\n".join([doc.page_content for doc in similar_contexts])

        if len(text) > Config.MAX_TEXT_LENGTH:
            text = text[:Config.MAX_TEXT_LENGTH] + "..."

        prompt = f"""í˜„ì¬ í…ìŠ¤íŠ¸ì™€ ì´ì „ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.

ì´ì „ ì»¨í…ìŠ¤íŠ¸:
{context}

í˜„ì¬ í…ìŠ¤íŠ¸:
{text}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
1. ì£¼ìš” ì•„ì´ë””ì–´ (3ê°œ)
2. ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ (2ê°œ)
3. ì´ì „ ì»¨í…ìŠ¤íŠ¸ì™€ì˜ ì—°ê´€ì„±"""

        try:
            response = self.client.chat.completions.create(
                model=Config.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì½˜í…ì¸  ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1000,
                temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"ì•„ì´ë””ì–´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None

    def summarize_transcript(self, text: str) -> str:
        """
        ì „ì‚¬ëœ í…ìŠ¤íŠ¸ì˜ ìš”ì•½ë³¸ ìƒì„±
        """
        try:
            prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”:

    í…ìŠ¤íŠ¸:
    {text[:4000]}  # í† í° ì œí•œì„ ê³ ë ¤í•˜ì—¬ ì˜ë¼ëƒ„

    ìš”ì•½ í˜•ì‹:
    1. í•µì‹¬ ì£¼ì œ
    2. ì£¼ìš” ë…¼ì  (3-4ê°œ)
    3. ê²°ë¡ 
    """
            response = self.client.chat.completions.create(
                model="gpt-4-1106-preview",  # ìµœì‹  ëª¨ë¸ ì‚¬ìš©
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ì½˜í…ì¸  ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=500,
                temperature=0.3  # ë” ì¼ê´€ëœ ìš”ì•½ì„ ìœ„í•´ ë‚®ì€ temperature ì‚¬ìš©
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None

    def generate_analysis_with_history(self, current_text: str, summary: str) -> str:
        """
        ìš”ì•½ë³¸ê³¼ ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ ì‹¬ì¸µ ë¶„ì„ ìƒì„±
        """
        try:
            # ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
            similar_contexts = self.conversation_manager.search_similar(
                current_text)
            context = "\n".join([doc.page_content for doc in similar_contexts])

            prompt = f"""í˜„ì¬ ì½˜í…ì¸ ì™€ ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ ì‹¬ì¸µ ë¶„ì„ì„ ì§„í–‰í•´ì£¼ì„¸ìš”.

    í˜„ì¬ ì½˜í…ì¸  ìš”ì•½:
    {summary}

    ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸:
    {context}

    ë‹¤ìŒ í•­ëª©ë“¤ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
    1. í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (3ê°œ)
    2. ì´ì „ ë‚´ìš©ê³¼ì˜ ì—°ê´€ì„± ë° ì°¨ì´ì 
    3. ì‹¤í–‰ ê°€ëŠ¥í•œ ì œì•ˆì‚¬í•­ (2-3ê°œ)
    4. ì¶”ê°€ íƒêµ¬ê°€ í•„ìš”í•œ ë¶€ë¶„
    """
            response = self.client.chat.completions.create(
                model="gpt-4-1106-preview",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ì½˜í…ì¸  ë¶„ì„ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1000,
                temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"ë¶„ì„ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None

    def generate_report(self, team_member: str, report_title: str, analysis: str) -> str:
        """
        ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³µì‹ ë³´ê³ ì„œ ìƒì„±
        """
        try:
            current_date = datetime.now().strftime("%Yë…„ %mì›” %dì¼")
            prompt = f"""ë‹¤ìŒ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³µì‹ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

    ê¸°ë³¸ ì •ë³´:
    - ì‘ì„±ì: {team_member}
    - ë³´ê³ ì„œ ì œëª©: {report_title}
    - ì‘ì„±ì¼: {current_date}

    ë¶„ì„ ë‚´ìš©:
    {analysis}

    ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:
    1. ë³´ê³ ì„œ í—¤ë” (ì œëª©, ì‘ì„±ì, ë‚ ì§œ)
    2. ìš”ì•½ (3-4ì¤„)
    3. ì£¼ìš” ë°œê²¬ì‚¬í•­ (3-4ê°œ)
    4. ì„¸ë¶€ ë¶„ì„ ë‚´ìš©
    5. ê²°ë¡  ë° ì œì•ˆì‚¬í•­
    6. í–¥í›„ ì—°êµ¬ ë°©í–¥

    ë³´ê³ ì„œëŠ” í•™ìˆ ì ì´ê³  ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

            response = self.client.chat.completions.create(
                model=Config.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ë³´ê³ ì„œ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=2000,
                temperature=0.5
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None

    def process_video(self, youtube_url: str) -> Optional[tuple[str, str, str]]:
        """
        ì˜ìƒ ì²˜ë¦¬ ë° ë¶„ì„ (ìš”ì•½ë³¸ê³¼ ì‹¬ì¸µ ë¶„ì„ í¬í•¨)
        """
        audio_path = None
        try:
            logger.info("ë‹¤ìš´ë¡œë“œ ì¤‘...")
            audio_path = self.download_and_process(youtube_url)

            logger.info("ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘...")
            transcribed_text = self.transcribe_audio(audio_path)

            logger.info("í…ìŠ¤íŠ¸ ìš”ì•½ ì¤‘...")
            summary = self.summarize_transcript(transcribed_text)

            logger.info("ì‹¬ì¸µ ë¶„ì„ ì¤‘...")
            analysis = self.generate_analysis_with_history(
                transcribed_text, summary)

            # ëŒ€í™” ë‚´ìš© ì €ì¥
            self.conversation_manager.add_conversation(
                transcribed_text,
                metadata={
                    "url": youtube_url,
                    "timestamp": datetime.now().isoformat(),
                    "summary": summary,
                    "analysis": analysis
                }
            )

            return transcribed_text, summary, analysis

        except Exception as e:
            logger.error(f"ì—ëŸ¬ ë°œìƒ: {str(e)}")
            return None, None, None
        finally:
            if audio_path and os.path.exists(audio_path):
                try:
                    os.remove(audio_path)
                except OSError as e:
                    logger.error(f"íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


def create_streamlit_app():
    st.set_page_config(
        page_title="YouTube ì˜ìƒ ë¶„ì„ê¸°",
        page_icon="ğŸ¥",
        layout="wide"
    )

    load_dotenv()
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        st.error("í™˜ê²½ ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    st.title("ğŸ¥ YouTube ì˜ìƒ ë¶„ì„ê¸°")
    st.markdown("YouTube ì˜ìƒì˜ ë‚´ìš©ì„ ë¶„ì„í•˜ê³  ì£¼ìš” ì•„ì´ë””ì–´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.")

    if 'history' not in st.session_state:
        st.session_state.history = []
    if 'extractor' not in st.session_state:
        st.session_state.extractor = YouTubeIdeaExtractor()

    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        st.success("API í‚¤ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

        if st.button("ğŸ—‘ ê¸°ë¡ ì‚­ì œ"):
            st.session_state.history = []
            st.success("ë¶„ì„ ê¸°ë¡ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")

    # ë©”ì¸ ì»¨í…ì¸ 
    col1, col2 = st.columns([2, 1])

    with col1:
        search_query = st.text_input(
            "ğŸ” ë¶„ì„í•˜ê³  ì‹¶ì€ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”",
            placeholder="ì˜ˆ: AI ì±—ë´‡ ê°œë°œ, íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë° ë“±"
        )

    if search_query:
        # ìƒˆ ê²€ìƒ‰ì–´ê°€ ì…ë ¥ë˜ë©´ í˜ì´ì§€ ë¦¬ì…‹
        if 'previous_query' not in st.session_state or st.session_state.previous_query != search_query:
            st.session_state.page = 1
            st.session_state.previous_query = search_query

        # í˜ì´ì§€ ìƒíƒœ ê´€ë¦¬
        if 'page' not in st.session_state:
            st.session_state.page = 1

        with st.spinner("ì˜ìƒ ê²€ìƒ‰ ì¤‘..."):
            try:
                videos = st.session_state.extractor.search_videos_with_pagination(
                    search_query,
                    page=st.session_state.page
                )

                if videos:
                    st.markdown("### ğŸ¬ ê²€ìƒ‰ëœ ì˜ìƒ")

                    for idx, video in enumerate(videos):
                        st.markdown("---")
                        col_thumb, col_info = st.columns([1, 2])

                        with col_thumb:
                            st.image(video['thumbnail'])

                        with col_info:
                            st.markdown(f"### {video['title']}")
                            st.markdown(f"**ì±„ë„**: {video['channel']}")

                            try:
                                duration = float(video['duration'])
                                minutes = int(duration // 60)
                                seconds = int(duration % 60)
                                st.markdown(f"**ê¸¸ì´**: {minutes}ë¶„ {seconds}ì´ˆ")
                            except (ValueError, TypeError):
                                st.markdown("**ê¸¸ì´**: ì •ë³´ ì—†ìŒ")

                            description = video.get('description', 'ì„¤ëª… ì—†ìŒ')
                            if description and len(description) > 200:
                                description = description[:200] + "..."
                            st.markdown(f"**ì„¤ëª…**: {description}")

                            # ë¹„ë””ì˜¤ ì •ë³´ ì €ì¥ì„ ìœ„í•œ ì„¸ì…˜ ìƒíƒœ ì¶”ê°€
                            if 'video_data' not in st.session_state:
                                st.session_state.video_data = {}

                            # ë¹„ë””ì˜¤ ë¶„ì„ ë²„íŠ¼ í´ë¦­ ì‹œ
                            if st.button("ğŸ¯ ì´ ì˜ìƒ ë¶„ì„í•˜ê¸°", key=f"analyze_{idx}"):
                                try:
                                    # í˜„ì¬ ë¹„ë””ì˜¤ ì •ë³´ ì €ì¥
                                    current_video_id = video['video_id']
                                    st.session_state.video_data[idx] = {
                                        'video_id': current_video_id,
                                        'url': video['url']
                                    }
                                    
                                    with st.spinner("ğŸµ ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì¤‘..."):
                                        # ì˜¬ë°”ë¥¸ ë¹„ë””ì˜¤ URL ì‚¬ìš© í™•ì¸
                                        video_url = st.session_state.video_data[idx]['url']
                                        audio_path = st.session_state.extractor.download_and_process(video_url)

                                    with st.spinner("ğŸ¯ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘..."):
                                        transcribed_text = st.session_state.extractor.transcribe_audio(
                                            audio_path)
                                        st.text_area(
                                            "ğŸ“ ë³€í™˜ëœ í…ìŠ¤íŠ¸",
                                            transcribed_text,
                                            height=200
                                        )

                                    with st.spinner("ğŸ“‹ í…ìŠ¤íŠ¸ ìš”ì•½ ì¤‘..."):
                                        summary = st.session_state.extractor.summarize_transcript(
                                            transcribed_text)
                                        if summary:
                                            st.markdown("### ğŸ“Œ ìš”ì•½")
                                            st.markdown(summary)

                                    with st.spinner("ğŸ’¡ ì‹¬ì¸µ ë¶„ì„ ì¤‘..."):
                                        similar_contexts = st.session_state.extractor.conversation_manager.search_similar(
                                            transcribed_text)
                                        analysis = st.session_state.extractor.analyze_with_summary(
                                            transcribed_text,
                                            summary,
                                            similar_contexts
                                        )

                                        # ë¶„ì„ ê²°ê³¼ë¥¼ session_stateì— ì €ì¥
                                        if 'current_analysis' not in st.session_state:
                                            st.session_state.current_analysis = {}

                                        # ë³´ê³ ì„œ ìƒì„± ì„¹ì…˜
                                        if analysis:
                                            st.markdown("### ğŸ“‘ ë³´ê³ ì„œ ìƒì„±")
                                            col1, col2 = st.columns(2)
                                            
                                            with col1:
                                                team_member = st.text_input("ì‘ì„±ì ì´ë¦„", key=f"team_{idx}")
                                            with col2:
                                                report_title = st.text_input("ë³´ê³ ì„œ ì œëª©", key=f"title_{idx}")
                                            
                                            if st.button("ë³´ê³ ì„œ ìƒì„±", key=f"report_{idx}"):
                                                if team_member and report_title:
                                                    with st.spinner("ë³´ê³ ì„œ ìƒì„± ì¤‘..."):
                                                        try:
                                                            report = st.session_state.extractor.generate_report(
                                                                team_member,
                                                                report_title,
                                                                analysis
                                                            )
                                                            
                                                            if report:
                                                                # ë³´ê³ ì„œë¥¼ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ì €ì¥
                                                                report_filename = f"report_{team_member}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
                                                                with open(report_filename, "w", encoding="utf-8") as f:
                                                                    f.write(report)
                                                                
                                                                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ìƒì„±
                                                                with open(report_filename, "rb") as f:
                                                                    st.download_button(
                                                                        label="ğŸ“¥ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                                                                        data=f,
                                                                        file_name=report_filename,
                                                                        mime="text/markdown"
                                                                    )
                                                                
                                                                # í™”ë©´ì—ë„ í‘œì‹œ
                                                                st.markdown("### ğŸ“Š ìƒì„±ëœ ë³´ê³ ì„œ")
                                                                st.markdown(report)
                                                                st.success("ë³´ê³ ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                                                
                                                        except Exception as e:
                                                            st.error(f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                                                else:
                                                    st.warning("ì‘ì„±ì ì´ë¦„ê³¼ ë³´ê³ ì„œ ì œëª©ì„ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
                                    if os.path.exists(audio_path):
                                        os.remove(audio_path)

                                except Exception as e:
                                    st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

                    # í˜ì´ì§€ë„¤ì´ì…˜ ì»¨íŠ¸ë¡¤
                    st.markdown("---")
                    col1, col2, col3 = st.columns([1, 2, 1])
                    with col1:
                        if st.session_state.page > 1:
                            if st.button("â—€ ì´ì „", key="prev_page"):
                                st.session_state.page -= 1
                                st.rerun()
                    with col2:
                        st.markdown(
                            f"<div style='text-align: center'>**í˜ì´ì§€ {st.session_state.page}**</div>", unsafe_allow_html=True)
                    with col3:
                        if len(videos) == 5:
                            if st.button("ë‹¤ìŒ â–¶", key="next_page"):
                                st.session_state.page += 1
                                st.rerun()

                else:
                    st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

            except Exception as e:
                st.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

    # ë¶„ì„ ê¸°ë¡
    with col2:
        st.markdown("### ğŸ“š ë¶„ì„ ê¸°ë¡")

        for idx, item in enumerate(reversed(st.session_state.history)):
            with st.expander(f"ë¶„ì„ #{len(st.session_state.history) - idx}"):
                if item.get('thumbnail'):
                    st.image(item['thumbnail'])
                st.markdown(f"**ê²€ìƒ‰ì–´**: {item['query']}")
                st.markdown(f"**ì œëª©**: {item['title']}")
                st.markdown(f"**ì‹œê°„**: {item['timestamp']}")

                tab1, tab2, tab3 = st.tabs(["ìš”ì•½", "ë¶„ì„", "ì „ì²´ í…ìŠ¤íŠ¸"])
                with tab1:
                    if item.get('summary'):
                        st.markdown(item['summary'])
                with tab2:
                    if item.get('analysis'):  # 'ideas' ëŒ€ì‹  'analysis' ì‚¬ìš©
                        st.markdown(item['analysis'])
                with tab3:
                    if item.get('text'):
                        st.text_area("ì›ë³¸ í…ìŠ¤íŠ¸", item['text'], height=200)

                # ë³´ê³ ì„œê°€ ìˆëŠ” ê²½ìš° í‘œì‹œ
                if item.get('report'):
                    with st.expander("ğŸ“‘ ìƒì„±ëœ ë³´ê³ ì„œ"):
                        st.markdown(item['report'])


if __name__ == "__main__":
    create_streamlit_app()
    