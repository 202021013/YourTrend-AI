from google.cloud import speech_v1, storage
import os
from pydub import AudioSegment
import tempfile
from dotenv import load_dotenv
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
import yt_dlp
import requests
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime
import logging
import isodate
import pandas as pd
import plotly.express as px
from collections import Counter
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

@dataclass
class VideoInfo:
    title: str
    url: str
    duration: int
    thumbnail_url: str
    description: str
    views: int
    published_at: datetime
    
    @property
    def duration_str(self) -> str:
        minutes = self.duration // 60
        seconds = self.duration % 60
        return f"{minutes}:{seconds:02d}"
    
    def _format_duration(self) -> str:
        return self.duration_str

@dataclass
class TrendAnalysis:
    trending_topics: Dict[str, int]
    avg_duration: float
    popular_times: Dict[str, int]
    engagement_rate: float

class YouTubeTranscriptExtractor:
    def __init__(self):
        """Google Cloud ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.llm_api_key = os.getenv('llm_api_key')
        self.speech_json_path = os.getenv('SPEECH_JSON_PATH')
        self.bucket_name = os.getenv('BUCKET_NAME')
        
        # Google Cloud ì¸ì¦ ì„¤ì •
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = self.speech_json_path
        self.speech_client = speech_v1.SpeechClient()
        self.storage_client = storage.Client()
        
    def download_and_convert_audio(self, video_url: str, audio_dir: str) -> Optional[str]:
        """YouTube ì˜ìƒì—ì„œ ì˜¤ë””ì˜¤ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ë³€í™˜"""
        try:
            # ë””ë ‰í† ë¦¬ ì¡´ì¬ í™•ì¸ ë° ìƒì„±
            os.makedirs(audio_dir, exist_ok=True)
            
            # íŒŒì¼ëª… ìƒì„±
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            temp_filename = f"temp_{timestamp}"
            converted_filename = f"converted_{timestamp}.wav"
            
            # ì „ì²´ ê²½ë¡œ ì„¤ì •
            temp_path = os.path.join(audio_dir, temp_filename)
            converted_path = os.path.join(audio_dir, converted_filename)
            
            # yt-dlp ì„¤ì • ìˆ˜ì •
            ydl_opts = {
                'format': 'bestaudio/best',
                'outtmpl': temp_path,
                'postprocessors': [{
                    'key': 'FFmpegExtractAudio',
                    'preferredcodec': 'wav',
                    'preferredquality': '192',
                }],
                'quiet': True,
                'no_warnings': True
            }
            
            # ë‹¤ìš´ë¡œë“œ ì‹œë„
            try:
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    ydl.download([video_url])
            except Exception as e:
                logger.error(f"YouTube ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                return None
                
            # ì‹¤ì œ ìƒì„±ëœ íŒŒì¼ ì°¾ê¸°
            wav_file = temp_path + '.wav'
            if not os.path.exists(wav_file):
                logger.error(f"ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {wav_file}")
                return None
                
            # ì˜¤ë””ì˜¤ ë³€í™˜
            try:
                audio = AudioSegment.from_wav(wav_file)
                audio = audio.set_frame_rate(16000).set_channels(1)
                audio.export(converted_path, format='wav')
                
                # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                try:
                    os.remove(wav_file)
                except OSError:
                    pass
                    
                return converted_path if os.path.exists(converted_path) else None
                
            except Exception as e:
                logger.error(f"ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨: {str(e)}")
                return None
                
        except Exception as e:
            logger.error(f"ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None

    def transcribe_long_audio(self, audio_path: str, language_code: str = 'ko-KR') -> Optional[str]:
        """ê¸´ ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        try:
            # Cloud Storageì— íŒŒì¼ ì—…ë¡œë“œ
            bucket = self.storage_client.bucket(self.bucket_name)
            audio_blob_name = f"temp_audio_{os.path.basename(audio_path)}"
            blob = bucket.blob(audio_blob_name)
            
            # ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ
            blob.upload_from_filename(audio_path)
            gcs_uri = f"gs://{self.bucket_name}/{audio_blob_name}"
            
            # ì˜¤ë””ì˜¤ ì„¤ì •
            audio = speech_v1.RecognitionAudio(uri=gcs_uri)
            config = speech_v1.RecognitionConfig(
                encoding=speech_v1.RecognitionConfig.AudioEncoding.LINEAR16,
                sample_rate_hertz=16000,
                language_code=language_code,
                enable_automatic_punctuation=True,
                model='latest_long',
                use_enhanced=True
            )
            
            # ë¹„ë™ê¸° ìŒì„± ì¸ì‹ ì‹œì‘
            operation = self.speech_client.long_running_recognize(
                config=config,
                audio=audio
            )
            
            st.info("ìŒì„± ì¸ì‹ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
            
            # ê²°ê³¼ ëŒ€ê¸°
            response = operation.result()
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            blob.delete()
            
            # ì „ì²´ í…ìŠ¤íŠ¸ ì¡°í•©
            transcript = ""
            for result in response.results:
                transcript += result.alternatives[0].transcript + "\n"
            
            return transcript.strip()
            
        except Exception as e:
            logger.error(f"ìŒì„± ì¸ì‹ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
        finally:
            # ì„ì‹œ íŒŒì¼ì´ ë‚¨ì•„ìˆëŠ” ê²½ìš° ì‚­ì œ ì‹œë„
            try:
                blob = bucket.blob(audio_blob_name)
                if blob.exists():
                    blob.delete()
            except:
                pass

class IdeaManager:
    def __init__(self):
        if 'saved_ideas' not in st.session_state:
            st.session_state.saved_ideas = []
    
    def save_idea(self, video_title: str, ideas: str) -> None:
        st.session_state.saved_ideas.append({
            "video_title": video_title,
            "ideas": ideas,
            "timestamp": datetime.now()
        })
    
    def delete_idea(self, index: int) -> None:
        if 0 <= index < len(st.session_state.saved_ideas):
            st.session_state.saved_ideas.pop(index)
            
    def get_all_ideas(self) -> List[Dict]:
        return st.session_state.saved_ideas

class EnhancedYouTubeIdeaGenerator:
    def __init__(self, openai_api_key: str, youtube_api_key: str):
        self.openai_api_key = openai_api_key
        self.youtube_api_key = youtube_api_key
        self.trend_cache = {}
        self.idea_history = []
        self.chain = ChatOpenAI(openai_api_key=openai_api_key)
        
        try:
            nltk.data.find('tokenizers/punkt')
        except LookupError:
            nltk.download('punkt')
            nltk.download('stopwords')
    
    def search_videos(self, query: str, max_results: int = 50) -> List[VideoInfo]:
        url = f"https://www.googleapis.com/youtube/v3/search"
        params = {
            "part": "snippet",
            "q": query,
            "key": self.youtube_api_key,
            "maxResults": max_results,
            "type": "video"
        }
        
        response = requests.get(url, params=params)
        videos = []
        
        for item in response.json().get("items", []):
            video_id = item["id"]["videoId"]
            stats_url = f"https://www.googleapis.com/youtube/v3/videos"
            stats_params = {
                "part": "statistics,contentDetails",
                "id": video_id,
                "key": self.youtube_api_key
            }
            
            stats_response = requests.get(stats_url, params=stats_params)
            stats_data = stats_response.json()["items"][0]
            
            duration = isodate.parse_duration(stats_data["contentDetails"]["duration"]).total_seconds()
            
            videos.append(VideoInfo(
                title=item["snippet"]["title"],
                url=f"https://www.youtube.com/watch?v={video_id}",
                duration=int(duration),
                thumbnail_url=item["snippet"]["thumbnails"]["high"]["url"],
                description=item["snippet"]["description"],
                views=int(stats_data["statistics"]["viewCount"]),
                published_at=datetime.strptime(item["snippet"]["publishedAt"], "%Y-%m-%dT%H:%M:%SZ")
            ))
        
        return videos

    def analyze_trends(self, query: str, days: int = 7) -> TrendAnalysis:
        cache_key = f"{query}_{days}"
        if cache_key in self.trend_cache:
            return self.trend_cache[cache_key]
            
        videos = self.search_videos(query=query)
        
        all_text = " ".join([v.title + " " + v.description for v in videos])
        tokens = word_tokenize(all_text.lower())
        stop_words = set(stopwords.words('english'))
        meaningful_words = [word for word in tokens if word.isalnum() and word not in stop_words]
        trending_topics = dict(Counter(meaningful_words).most_common(10))
        
        analysis = TrendAnalysis(
            trending_topics=trending_topics,
            avg_duration=sum(v.duration for v in videos) / len(videos) if videos else 0,
            popular_times=dict(Counter([v.published_at.hour for v in videos])),
            engagement_rate=len(videos) / sum(v.views for v in videos) if videos else 0
        )
        
        self.trend_cache[cache_key] = analysis
        return analysis

    def visualize_trends(self, trends: TrendAnalysis) -> Dict[str, px.Figure]:
        figures = {}
        
        keyword_df = pd.DataFrame(
            list(trends.trending_topics.items()),
            columns=['Keyword', 'Frequency']
        )
        figures['keywords'] = px.bar(
            keyword_df,
            x='Keyword',
            y='Frequency',
            title='íŠ¸ë Œë”© í‚¤ì›Œë“œ'
        )
        
        time_df = pd.DataFrame(
            list(trends.popular_times.items()),
            columns=['Hour', 'Uploads']
        )
        figures['upload_times'] = px.line(
            time_df,
            x='Hour',
            y='Uploads',
            title='ì¸ê¸° ì—…ë¡œë“œ ì‹œê°„ëŒ€'
        )
        
        return figures

def main():
    st.set_page_config(page_title="YouTube í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ ìƒì„±ê¸°", page_icon="ğŸš€", layout="wide")
    
    st.title("ğŸš€ YouTube í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ ìƒì„±ê¸°")
    st.markdown("""
        íŠ¸ë Œë“œ ë¶„ì„ê³¼ AIë¥¼ í™œìš©í•œ ìŠ¤ë§ˆíŠ¸ í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ ìƒì„±ê¸°
        * ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ë¶„ì„
        * ì‹œì¥ì„± ë¶„ì„ í¬í•¨
        * ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
    """)
    
    with st.sidebar:
        st.header("ğŸ¯ ê²€ìƒ‰ & ë¶„ì„ ì„¤ì •")
        query = st.text_input("ê²€ìƒ‰ì–´", placeholder="ê¸°ìˆ /ë„ë©”ì¸ ì…ë ¥")
        trend_days = st.slider("íŠ¸ë Œë“œ ë¶„ì„ ê¸°ê°„(ì¼)", 1, 30, 7)
        
        st.markdown("---")
        st.markdown("### ğŸ“Š íŠ¸ë Œë“œ í•„í„°")
        min_views = st.number_input("ìµœì†Œ ì¡°íšŒìˆ˜", 0, 1000000, 1000)
        engagement_threshold = st.slider("ìµœì†Œ ì°¸ì—¬ìœ¨(%)", 0.0, 100.0, 1.0)
    
    if query:
        generator = EnhancedYouTubeIdeaGenerator(
            openai_api_key=os.getenv("OPENAI_API_KEY"),
            youtube_api_key=os.getenv("YOUTUBE_API_KEY")
        )
        
        with st.spinner("íŠ¸ë Œë“œ ë¶„ì„ ì¤‘..."):
            trends = generator.analyze_trends(query, trend_days)
            figures = generator.visualize_trends(trends)
            
            col1, col2 = st.columns(2)
            with col1:
                st.plotly_chart(figures['keywords'])
            with col2:
                st.plotly_chart(figures['upload_times'])
            
            context = st.text_area("ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸", placeholder="íŠ¹ë³„í•œ ìš”êµ¬ì‚¬í•­ì´ë‚˜ ì œì•½ì¡°ê±´ì„ ì…ë ¥í•˜ì„¸ìš”")
            
            if st.button("ì•„ì´ë””ì–´ ìƒì„±"):
                with st.spinner("AIê°€ ì•„ì´ë””ì–´ë¥¼ ìƒì„±ì¤‘ì…ë‹ˆë‹¤..."):
                    prompt = generator.generate_prompt(query, trends, context)
                    response = generator.chain.invoke({"input": prompt})
                    
                    st.markdown("### ğŸ’¡ ìƒì„±ëœ ì•„ì´ë””ì–´")
                    st.markdown(response.content)

if __name__ == "__main__":
    main()