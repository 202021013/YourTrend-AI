import streamlit as st
from openai import OpenAI
import time
from typing import List, Dict
from dotenv import load_dotenv
import os

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

class AIAgent:
    def __init__(self, name: str, role: str):
        self.name = name
        self.role = role
        self.client = OpenAI()  # API í‚¤ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ ìë™ìœ¼ë¡œ ë¡œë“œë¨
        self.conversation_history: List[Dict] = []
        
    def generate_response(self, topic: str, other_response: str = "") -> str:
        messages = [
            {"role": "system", "content": f"""ë‹¹ì‹ ì€ {self.name}ì…ë‹ˆë‹¤. {self.role}
            ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì™€ ëŒ€í™”í•˜ë©´ì„œ ì£¼ì œì— ëŒ€í•´ ê¹Šì´ ìˆê²Œ ë¶„ì„í•˜ê³  í† ë¡ í•˜ì„¸ìš”.
            ê°ìì˜ ê´€ì ì—ì„œ ì¤‘ìš”í•œ í¬ì¸íŠ¸ë¥¼ ì œì‹œí•˜ê³ , ìƒëŒ€ë°©ì˜ ì˜ê²¬ì„ ë°œì „ì‹œì¼œ ë‚˜ê°€ì•¼ í•©ë‹ˆë‹¤.
            ìµœì¢…ì ìœ¼ë¡œëŠ” í˜ì‹ ì ì¸ ì•„ì´ë””ì–´ ë„ì¶œì„ ìœ„í•œ ê¸°ë°˜ì„ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤."""},
            {"role": "user", "content": f"ì£¼ì œ: {topic}"}
        ]
        
        messages.extend(self.conversation_history)
        
        if other_response:
            messages.append({"role": "user", "content": f"ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì˜ ì˜ê²¬: {other_response}\nì´ ì˜ê²¬ì„ ê³ ë ¤í•˜ì—¬ ë‹¹ì‹ ì˜ ì „ë¬¸ì„±ì„ ë°”íƒ•ìœ¼ë¡œ ì˜ê²¬ì„ ë°œì „ì‹œì¼œì£¼ì„¸ìš”."})
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=messages,
                max_tokens=200,
                temperature=0.7
            )
            
            generated_response = response.choices[0].message.content.strip()
            return generated_response
        
        except Exception as e:
            return f"Error generating response: {str(e)}"

def generate_innovative_conclusion(topic: str, conversation_history: List[str], custom_prompt: str) -> str:
    client = OpenAI()
    
    conversation_text = "\n".join(f"ë°œì–¸ {idx}: {msg}" for idx, msg in enumerate(conversation_history, 1))
    
    # ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
    system_prompt = custom_prompt if custom_prompt else """ë‹¹ì‹ ì€ í˜ì‹ ì ì¸ ì•„ì´ë””ì–´ë¥¼ ë„ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ë¶„ì„ê°€ì™€ ì‹¤ë¬´ìì˜ ëŒ€í™”ë¥¼ ì¢…í•©í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì€ ê²°ê³¼ë¬¼ì„ ë„ì¶œí•´ì£¼ì„¸ìš”:
        1. ëŒ€í™”ì—ì„œ ë°œê²¬ëœ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (2-3ì¤„)
        2. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ í˜ì‹ ì ì¸ ì•„ì´ë””ì–´ ì œì•ˆ (3-4ê°œ)
        3. ì‹¤í˜„ ê°€ëŠ¥í•œ ì‹¤í–‰ ë°©ì•ˆ (2-3ì¤„)
        ì•„ì´ë””ì–´ëŠ” êµ¬ì²´ì ì´ê³  ì‹¤í˜„ ê°€ëŠ¥í•˜ë©´ì„œë„ ì°½ì˜ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤."""
    
    prompt = (
        f"ì£¼ì œ: {topic}\n"
        f"ëŒ€í™” ë‚´ìš©:\n{conversation_text}\n"
        "ìœ„ ëŒ€í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ í˜ì‹ ì ì¸ ì•„ì´ë””ì–´ì™€ ì‹¤í–‰ ë°©ì•ˆì„ ë„ì¶œí•´ì£¼ì„¸ìš”."
    )
    
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": prompt}
    ]
    
    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            max_tokens=800,
            temperature=0.8
        )
        
        return response.choices[0].message.content.strip()
        
    except Exception as e:
        return f"Error generating conclusion: {str(e)}"

def create_message_container(role: str, message: str):
    """ë©”ì‹œì§€ë¥¼ ìŠ¤íƒ€ì¼ì´ ì ìš©ëœ ì»¨í…Œì´ë„ˆì— í‘œì‹œí•©ë‹ˆë‹¤."""
    if role == "ë¶„ì„ê°€":
        st.markdown(
            f"""
            <div style="
                background-color: #E8F4F9;
                padding: 15px;
                border-radius: 10px;
                margin: 10px 0;
                border-left: 4px solid #2196F3;
            ">
                <strong>ğŸ“Š ë¶„ì„ê°€</strong><br>{message}
            </div>
            """,
            unsafe_allow_html=True
        )
    else:  # ì‹¤ë¬´ì
        st.markdown(
            f"""
            <div style="
                background-color: #FFF3E0;
                padding: 15px;
                border-radius: 10px;
                margin: 10px 0;
                border-left: 4px solid #FF9800;
            ">
                <strong>ğŸ› ï¸ ì‹¤ë¬´ì</strong><br>{message}
            </div>
            """,
            unsafe_allow_html=True
        )

def create_round_separator(round_number: int):
    """ë¼ìš´ë“œ êµ¬ë¶„ì„ ê³¼ í—¤ë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    st.markdown(
        f"""
        <div style="
            margin: 30px 0 20px 0;
            padding: 10px 0;
            border-top: 2px solid #e0e0e0;
        ">
            <h3 style="color: #1976D2; margin: 10px 0;">ğŸ”„ ë¼ìš´ë“œ {round_number}</h3>
        </div>
        """,
        unsafe_allow_html=True
    )

def main():
    st.title("ğŸ’¡ AI ì•„ì´ë””ì–´ ë°œêµ´ ì‹œìŠ¤í…œ")
    st.markdown("### ë¶„ì„ê°€ì™€ ì‹¤ë¬´ìì˜ ëŒ€í™”ë¥¼ í†µí•œ í˜ì‹ ì ì¸ ì•„ì´ë””ì–´ ë„ì¶œ")
    
    # API í‚¤ í™•ì¸
    if not os.getenv("OPENAI_API_KEY"):
        st.error("OPENAI_API_KEYê°€ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'started' not in st.session_state:
        st.session_state.started = False
        st.session_state.conversation_history = []
        st.session_state.current_round = 0
        st.session_state.is_processing = False
    
    # ì—ì´ì „íŠ¸ ì´ˆê¸°í™” (ì´ì „ê³¼ ë™ì¼)
    analyst = AIAgent(
        "ë¶„ì„ê°€", 
        """ë‹¹ì‹ ì€ ë°ì´í„°ì™€ íŠ¸ë Œë“œë¥¼ ê¹Šì´ ìˆê²Œ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì‹œì¥ ë™í–¥, ì†Œë¹„ì í–‰ë™, ê¸°ìˆ  íŠ¸ë Œë“œ ë“±ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.
        í•­ìƒ ë°ì´í„°ì— ê¸°ë°˜í•œ ê°ê´€ì ì¸ ì˜ê²¬ì„ ì œì‹œí•˜ë˜, ë¯¸ë˜ ê°€ëŠ¥ì„±ë„ ê³ ë ¤í•©ë‹ˆë‹¤."""
    )
    
    practitioner = AIAgent(
        "ì‹¤ë¬´ì", 
        """ë‹¹ì‹ ì€ í˜„ì¥ ê²½í—˜ì´ í’ë¶€í•œ ì‹¤ë¬´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì‹¤ì œ ì ìš© ê°€ëŠ¥ì„±, ìì› íš¨ìœ¨ì„±, ì‹¤í–‰ ì‹œì˜ ë¬¸ì œì  ë“±ì„ ê³ ë ¤í•©ë‹ˆë‹¤.
        í˜„ì‹¤ì ì¸ ì œì•½ì‚¬í•­ì„ ê³ ë ¤í•˜ë˜, í˜ì‹ ì ì¸ í•´ê²°ë°©ì•ˆì„ ì„ í˜¸í•©ë‹ˆë‹¤."""
    )
    
    # ì£¼ì œ ì…ë ¥
    col1, col2 = st.columns([2, 1])
    with col1:
        topic = st.text_input("íƒêµ¬í•  ì£¼ì œë‚˜ í•´ê²°í•  ë¬¸ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”:", "ë¯¸ë˜ì˜ ìŠ¤ë§ˆíŠ¸ ì‹œí‹° ì„¤ê³„")
    
    # ì•„ì´ë””ì–´ ìƒì„± ë°©í–¥ ì„¤ì •
    with st.expander("ğŸ¯ ì•„ì´ë””ì–´ ìƒì„± ë°©í–¥ ì„¤ì •", expanded=True):
        custom_prompt = st.text_area(
            "ì•„ì´ë””ì–´ ìƒì„±ì„ ìœ„í•œ êµ¬ì²´ì ì¸ ë°©í–¥ì„ ì„¤ì •í•˜ì„¸ìš”:",
            """ë‹¹ì‹ ì€ í˜ì‹ ì ì¸ ì•„ì´ë””ì–´ë¥¼ ë„ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë¶„ì„ê°€ì™€ ì‹¤ë¬´ìì˜ ëŒ€í™”ë¥¼ ì¢…í•©í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì€ ê²°ê³¼ë¬¼ì„ ë„ì¶œí•´ì£¼ì„¸ìš”:
1. ëŒ€í™”ì—ì„œ ë°œê²¬ëœ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (2-3ì¤„)
2. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ í˜ì‹ ì ì¸ ì•„ì´ë””ì–´ ì œì•ˆ (3-4ê°œ)
3. ì‹¤í˜„ ê°€ëŠ¥í•œ ì‹¤í–‰ ë°©ì•ˆ (2-3ì¤„)
ì•„ì´ë””ì–´ëŠ” êµ¬ì²´ì ì´ê³  ì‹¤í˜„ ê°€ëŠ¥í•˜ë©´ì„œë„ ì°½ì˜ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤.""",
            height=200
        )
        st.info("ğŸ’¡ í”„ë¡¬í”„íŠ¸ë¥¼ ìˆ˜ì •í•˜ì—¬ ì›í•˜ëŠ” ë°©í–¥ì˜ ì•„ì´ë””ì–´ë¥¼ ìƒì„±í•˜ë„ë¡ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    # ìƒˆë¡œìš´ ì£¼ì œë¡œ ì‹œì‘í•˜ê¸° ë²„íŠ¼
    with col2:
        if st.button("ìƒˆë¡œìš´ ì£¼ì œë¡œ ì‹œì‘í•˜ê¸°"):
            st.session_state.started = False
            st.session_state.conversation_history = []
            st.session_state.current_round = 0
            st.session_state.is_processing = False
            st.rerun()

    # ëŒ€í™” ì‹œì‘ ë²„íŠ¼
    if not st.session_state.started and st.button("ëŒ€í™” ì‹œì‘", type="primary"):
        st.session_state.started = True
        st.session_state.is_processing = True
        st.rerun()
    
    # ëŒ€í™” ì§„í–‰ (ì´ì „ ì½”ë“œì™€ ë™ì¼í•˜ê²Œ ìœ ì§€í•˜ë˜, conclusion ìƒì„± ì‹œ custom_prompt ì „ë‹¬)
    if st.session_state.started:
        # ì§„í–‰ ìƒíƒœ í‘œì‹œ
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # ê° ë¼ìš´ë“œ ì§„í–‰
        while st.session_state.current_round < 3 and st.session_state.is_processing:
            progress_value = st.session_state.current_round / 3
            progress_bar.progress(progress_value)
            
            status_text.text(f"ë¼ìš´ë“œ {st.session_state.current_round + 1} ì§„í–‰ ì¤‘...")
            
            # ì´ì „ ë¼ìš´ë“œë“¤ì˜ ë‚´ìš©ì„ ë¨¼ì € í‘œì‹œ
            for past_round in range(st.session_state.current_round):
                create_round_separator(past_round + 1)
                past_analyst = st.session_state.conversation_history[past_round * 2]
                past_practitioner = st.session_state.conversation_history[past_round * 2 + 1]
                create_message_container("ë¶„ì„ê°€", past_analyst)
                create_message_container("ì‹¤ë¬´ì", past_practitioner)
            
            # í˜„ì¬ ë¼ìš´ë“œ í‘œì‹œ
            create_round_separator(st.session_state.current_round + 1)
            
            # ë¶„ì„ê°€ì˜ ì‘ë‹µ
            with st.spinner('ë¶„ì„ê°€ê°€ ì‘ë‹µì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...'):
                response_analyst = analyst.generate_response(
                    topic, 
                    st.session_state.conversation_history[-1] if st.session_state.conversation_history else ""
                )
                create_message_container("ë¶„ì„ê°€", response_analyst)
                st.session_state.conversation_history.append(response_analyst)
            
            # ì‹¤ë¬´ìì˜ ì‘ë‹µ
            with st.spinner('ì‹¤ë¬´ìê°€ ì‘ë‹µì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...'):
                response_practitioner = practitioner.generate_response(topic, response_analyst)
                create_message_container("ì‹¤ë¬´ì", response_practitioner)
                st.session_state.conversation_history.append(response_practitioner)
            
            st.session_state.current_round += 1
            time.sleep(1)  # UI ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
            
            if st.session_state.current_round < 3:
                st.rerun()
        
        # ëª¨ë“  ë¼ìš´ë“œê°€ ì™„ë£Œë˜ë©´ ê²°ë¡  ë„ì¶œ
        if st.session_state.current_round == 3:
            progress_bar.progress(1.0)
            status_text.text("ëª¨ë“  ë¼ìš´ë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìµœì¢… ê²°ë¡ ì„ ë„ì¶œí•©ë‹ˆë‹¤...")
            
            st.markdown("---")
            st.markdown("### ğŸš€ í˜ì‹ ì  ì•„ì´ë””ì–´ ë„ì¶œ")
            
            with st.spinner('ìµœì¢… ê²°ë¡ ì„ ë„ì¶œí•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
                conclusion = generate_innovative_conclusion(
                    topic, 
                    st.session_state.conversation_history,
                    custom_prompt
                )
                
                # ê²°ë¡ ì„ ì„¹ì…˜ë³„ë¡œ ë‚˜ëˆ„ì–´ í‘œì‹œ
                sections = conclusion.split('\n\n')
                for section in sections:
                    if 'ì¸ì‚¬ì´íŠ¸' in section.lower():
                        st.markdown("#### ğŸ” í•µì‹¬ ì¸ì‚¬ì´íŠ¸")
                        st.info(section.split(':', 1)[1] if ':' in section else section)
                    elif 'ì•„ì´ë””ì–´' in section.lower():
                        st.markdown("#### ğŸ’¡ í˜ì‹ ì  ì•„ì´ë””ì–´")
                        st.success(section.split(':', 1)[1] if ':' in section else section)
                    elif 'ì‹¤í–‰' in section.lower():
                        st.markdown("#### âš¡ ì‹¤í–‰ ë°©ì•ˆ")
                        st.warning(section.split(':', 1)[1] if ':' in section else section)
                    else:
                        st.write(section)
            
            status_text.text("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. 'ìƒˆë¡œìš´ ì£¼ì œë¡œ ì‹œì‘í•˜ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ ìƒˆë¡œìš´ ì£¼ì œë¥¼ íƒêµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()